{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Week4_Data_manipulation.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNhCvfcrCjupo3b4wLLFRNG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/irinavalenzuela/Applied-Data-Science-Python/blob/main/Week4_Data_manipulation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction to Data Science in Python\n",
        "\n",
        "## Week 4: Beyond Data Manipulation"
      ],
      "metadata": {
        "id": "z0w09YjL85lX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Basic Statistical Testing"
      ],
      "metadata": {
        "id": "87gjgInb9KW7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We use statistics in a lot of different ways in data science, and on this lecture, I want to refresh your\n",
        "# knowledge of hypothesis testing, which is a core data analysis activity behind experimentation. The goal of\n",
        "# hypothesis testing is to determine if, for instance, the two different conditions we have in an experiment \n",
        "# have resulted in different impacts\n",
        "\n",
        "# Let's import our usual numpy and pandas libraries\n",
        "\n",
        "# Now let's bring in some new libraries from scipy"
      ],
      "metadata": {
        "id": "YppxgKLS9G1b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now, scipy is an interesting collection of libraries for data science and you'll use most or perpahs all of\n",
        "# these libraries. It includes numpy and pandas, but also plotting libraries such as matplotlib, and a\n",
        "# number of scientific library functions as well"
      ],
      "metadata": {
        "id": "BD0Ztfpy9hnK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# When we do hypothesis testing, we actually have two statements of interest: the first is our actual\n",
        "# explanation, which we call the alternative hypothesis, and the second is that the explanation we have is not\n",
        "# sufficient, and we call this the null hypothesis. Our actual testing method is to determine whether the null\n",
        "# hypothesis is true or not. If we find that there is a difference between groups, then we can reject the null\n",
        "# hypothesis and we accept our alternative.\n",
        "\n",
        "# Let's see an example of this; we're going to use some grade data"
      ],
      "metadata": {
        "id": "rbrtQIZK9jNa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# If we take a look at the data frame inside, we see we have six different assignments. Lets look at some\n",
        "# summary statistics for this DataFrame"
      ],
      "metadata": {
        "id": "DdItrbG_9k-_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For the purpose of this lecture, let's segment this population into two pieces. Let's say those who finish\n",
        "# the first assignment by the end of December 2015, we'll call them early finishers, and those who finish it \n",
        "# sometime after that, we'll call them late finishers.\n"
      ],
      "metadata": {
        "id": "wsBYYfls9m6p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# So, you have lots of skills now with pandas, how would you go about getting the late_finishers dataframe?\n",
        "# Why don't you pause the video and give it a try."
      ],
      "metadata": {
        "id": "ewIrkhow9odw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Here's my solution. First, the dataframe df and the early_finishers share index values, so I really just\n",
        "# want everything in the df which is not in early_finishers"
      ],
      "metadata": {
        "id": "2ZduYqjr9q4h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# There are lots of other ways to do this. For instance, you could just copy and paste the first projection\n",
        "# and change the sign from less than to greater than or equal to. This is ok, but if you decide you want to\n",
        "# change the date down the road you have to remember to change it in two places. You could also do a join of\n",
        "# the dataframe df with early_finishers - if you do a left join you only keep the items in the left dataframe,\n",
        "# so this would have been a good answer. You also could have written a function that determines if someone is\n",
        "# early or late, and then called .apply() on the dataframe and added a new column to the dataframe. This is a\n",
        "# pretty reasonable answer as well."
      ],
      "metadata": {
        "id": "-s9x4EcY9sNl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# As you've seen, the pandas data frame object has a variety of statistical functions associated with it. If\n",
        "# we call the mean function directly on the data frame, we see that each of the means for the assignments are\n",
        "# calculated. Let's compare the means for our two populations"
      ],
      "metadata": {
        "id": "Z5UO-Ssi9t7r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ok, these look pretty similar. But, are they the same? What do we mean by similar? This is where the\n",
        "# students' t-test comes in. It allows us to form the alternative hypothesis (\"These are different\") as well\n",
        "# as the null hypothesis (\"These are the same\") and then test that null hypothesis.\n",
        "\n",
        "# When doing hypothesis testing, we have to choose a significance level as a threshold for how much of a\n",
        "# chance we're willing to accept. This significance level is typically called alpha. #For this example, let's\n",
        "# use a threshold of 0.05 for our alpha or 5%. Now this is a commonly used number but it's really quite\n",
        "# arbitrary.\n",
        "\n",
        "# The SciPy library contains a number of different statistical tests and forms a basis for hypothesis testing\n",
        "# in Python and we're going to use the ttest_ind() function which does an independent t-test (meaning the\n",
        "# populations are not related to one another). The result of ttest_index() are the t-statistic and a p-value.\n",
        "# It's this latter value, the probability, which is most important to us, as it indicates the chance (between\n",
        "# 0 and 1) of our null hypothesis being True.\n",
        "\n",
        "# Let's bring in our ttest_ind function\n",
        "\n",
        "# Let's run this function with our two populations, looking at the assignment 1 grades"
      ],
      "metadata": {
        "id": "KHvgnuY29vd1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# So here we see that the probability is 0.18, and this is above our alpha value of 0.05. This means that we\n",
        "# cannot reject the null hypothesis. The null hypothesis was that the two populations are the same, and we\n",
        "# don't have enough certainty in our evidence (because it is greater than alpha) to come to a conclusion to\n",
        "# the contrary. This doesn't mean that we have proven the populations are the same."
      ],
      "metadata": {
        "id": "OE5D2IVs9xZp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Why don't we check the other assignment grades?"
      ],
      "metadata": {
        "id": "5V_UKbFM90-U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ok, so it looks like in this data we do not have enough evidence to suggest the populations differ with\n",
        "# respect to grade. Let's take a look at those p-values for a moment though, because they are saying things\n",
        "# that can inform experimental design down the road. For instance, one of the assignments, assignment 3, has a\n",
        "# p-value around 0.1. This means that if we accepted a level of chance similarity of 11% this would have been\n",
        "# considered statistically significant. As a research, this would suggest to me that there is something here\n",
        "# worth considering following up on. For instance, if we had a small number of participants (we don't) or if\n",
        "# there was something unique about this assignment as it relates to our experiment (whatever it was) then\n",
        "# there may be followup experiments we could run."
      ],
      "metadata": {
        "id": "yhR-37Cy92QA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# P-values have come under fire recently for being insuficient for telling us enough about the interactions\n",
        "# which are happening, and two other techniques, confidence intervalues and bayesian analyses, are being used\n",
        "# more regularly. One issue with p-values is that as you run more tests you are likely to get a value which\n",
        "# is statistically significant just by chance.\n",
        "\n",
        "# Lets see a simulation of this. First, lets create a data frame of 100 columns, each with 100 numbers"
      ],
      "metadata": {
        "id": "zYad4NiX94Js"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pause this and reflect -- do you understand the list comprehension and how I created this DataFrame? You\n",
        "# don't have to use a list comprehension to do this, but you should be able to read this and figure out how it\n",
        "# works as this is a commonly used approach on web forums."
      ],
      "metadata": {
        "id": "Scf2eWy4967l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ok, let's create a second dataframe"
      ],
      "metadata": {
        "id": "FFrMI8ry98PV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}